{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download a timeseries of (1) daily deaths, (2) confirmed cases, (3) recovered per country (from John Hopkins Covid-19 Data Github repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bokeh\n",
    "\n",
    "# Download daily deaths per country from Github repo raw csv file and save to Pandas dataframe\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "url2 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "url3 = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv'\n",
    "\n",
    "deaths_df = [pd.read_csv(url, error_bad_lines=False),'deaths']\n",
    "confirmed_df = [pd.read_csv(url2, error_bad_lines=False), 'confirmed']\n",
    "recovered_df = [pd.read_csv(url3, error_bad_lines=False), 'recovered']\n",
    "\n",
    "list_of_dataframes = [deaths_df, confirmed_df, recovered_df]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create functions to unpivot and prepare data for the 3 dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (a) Aggregate state data for countries which have negligible data & unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract df of Countries without state info - remove China, Aus and Canada\n",
    "\n",
    "def agg_countries_and_unpivot(dataframe):\n",
    "\n",
    "    list_countries_with_state_info = ['China','Australia','Canada']\n",
    "\n",
    "    df_countries_without_state_info = dataframe[~dataframe['Country/Region'].isin(list_countries_with_state_info)]\n",
    "\n",
    "    # Aggregate (squash) data of countries with negligible state Info (A)\n",
    "    df_countries_without_state_info = df_countries_without_state_info.groupby('Country/Region').sum()\n",
    "    df_countries_without_state_info = df_countries_without_state_info.reset_index()\n",
    "    df_countries_without_state_info.insert(1, 'Province/State',np.nan)\n",
    "\n",
    "    # Get dataframe of Countries with State Info (B)\n",
    "    df_countries_with_state_info = dataframe[dataframe['Country/Region'].isin(list_countries_with_state_info)]\n",
    "\n",
    "    # Append aggregated Countries (A) with (B) dataframes\n",
    "    combined_df = df_countries_with_state_info.append(df_countries_without_state_info)\n",
    "    combined_df = combined_df.drop([\"Lat\", \"Long\"], axis=1)\n",
    "\n",
    "    # Get date headers\n",
    "    date_headers = list(combined_df.columns[2:].values)\n",
    "\n",
    "    long_df = pd.melt(combined_df, id_vars= ['Country/Region','Province/State'], value_vars= date_headers)\n",
    "    return long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (b) Rename columns & add change column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_add_change_column(dataframe, dict_key):\n",
    "    header_total_dictionary = {'deaths': 'total_deaths', 'confirmed': 'total_confirmed', 'recovered': 'total_recovered' }\n",
    "    header_change_dictionary = {'deaths': 'deaths_change', 'confirmed': 'confirmed_change','recovered': 'recovered_change' }\n",
    "\n",
    "    # Rename Columns\n",
    "    renamed_df = dataframe.rename(columns={\"Country/Region\": \"country\", \"Province/State\": \"state\",\"variable\": \"date\", \"value\": header_total_dictionary[dict_key]}, errors=\"raise\")\n",
    "\n",
    "    # Change date column type\n",
    "    renamed_df['date'] = pd.to_datetime(renamed_df['date'])\n",
    "\n",
    "    # Include change column\n",
    "    renamed_df.insert(4, header_change_dictionary[dict_key],0)\n",
    "    return renamed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. (c) Calculate daily change for each country (and for state, if applicable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate xxx_change (deaths, confirmed, recovered) for each country in 'countries' list\n",
    "\n",
    "# Get list of unique country names\n",
    "def calc_daily_change_column(dataframe, dict_key):\n",
    "    header_total_dictionary = {'deaths': 'total_deaths', 'confirmed': 'total_confirmed', 'recovered': 'total_recovered' }\n",
    "    \n",
    "    copy_of_dataframe = dataframe\n",
    "    \n",
    "    full_country_list = list(copy_of_dataframe['country'].unique())\n",
    "\n",
    "    for country in full_country_list:\n",
    "\n",
    "        if ( country not in list_countries_with_state_info ): \n",
    "\n",
    "            # Set temporary df for country\n",
    "            temp_df = copy_of_dataframe.loc[copy_of_dataframe['country'] == country]\n",
    "\n",
    "            # Find difference between rows (returns difference results dataframe)\n",
    "            diff = temp_df[header_total_dictionary[dict_key]].diff()\n",
    "\n",
    "            # Apply difference calculation to original copy_of_dataframe according to index\n",
    "            copy_of_dataframe.iloc[diff.index,4] = diff\n",
    "\n",
    "        else: \n",
    "            # Deal with Australia, China and Canada (purely state data)\n",
    "            # Set temporary df for country\n",
    "            temp_country_df = copy_of_dataframe.loc[copy_of_dataframe['country'] == country]\n",
    "\n",
    "            # Get unique list of states\n",
    "            states_list = list(temp_country_df['state'].unique())\n",
    "\n",
    "            for state in states_list:\n",
    "                temp_state_df = temp_country_df.loc[copy_of_dataframe['state'] == state]\n",
    "\n",
    "                diff = temp_state_df[header_total_dictionary[dict_key]].diff()\n",
    "\n",
    "                copy_of_dataframe.iloc[diff.index,4] = diff \n",
    "\n",
    "    # Remove NaN values from dataframe\n",
    "    copy_of_dataframe = copy_of_dataframe.fillna(0)\n",
    "    \n",
    "    return copy_of_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run calculations for all 3 dataframes with defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run calculations for all 3 dataframes with defined functions\n",
    "\n",
    "for dataframe in list_of_dataframes:\n",
    "    unpivoted_df = agg_countries_and_unpivot(dataframe[0])\n",
    "    renamed_unpivoted_df = rename_add_change_column(unpivoted_df, dataframe[1])\n",
    "    calculated_df = calc_daily_change_column(renamed_unpivoted_df, dataframe[1])\n",
    "    if dataframe[1] == 'deaths':\n",
    "        calculated_deaths_df = calculated_df\n",
    "    elif dataframe[1] == 'confirmed':\n",
    "        calculated_confirmed_df = calculated_df\n",
    "    elif dataframe[1] == 'recovered':\n",
    "        calculated_recovered_df = calculated_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Merge all 3 calculated dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join deaths, confirmed & recovered results\n",
    "interim_result = pd.merge(calculated_deaths_df, calculated_confirmed_df, on=['country', 'state','date'])\n",
    "final_result = pd.merge(interim_result, calculated_recovered_df, on=['country', 'state','date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write daily deaths dataframe to CSV file (for reference)\n",
    "final_result.to_csv('time_series_covid19_deaths_confirmed_recovered_global.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write to Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some useful functions\n",
    "def check_latest_country_data(dataframe, country):\n",
    "    return dataframe[dataframe['country']==country].sort_values(by='date',ascending=False)[0:50]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-jupyter",
   "language": "python",
   "name": "env-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
